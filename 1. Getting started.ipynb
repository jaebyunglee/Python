{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow: GETTING STARTED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is an open-source machine learning library for research and production. (https://www.tensorflow.org/tutorials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conceptual diagram of Tensorflow 2.0**\n",
    "\n",
    "![](https://miro.medium.com/max/700/0*fJ5u2WE51Oz44dr_)\n",
    "\n",
    "- Easy model building with `Keras` and `eager execution`.\n",
    "- Robust model deployment in production on any platform.\n",
    "- Powerful experimentation for research.\n",
    "- `Simplifying the API` by cleaning up deprecated APIs and reducing duplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [참고] Eager execution?\n",
    "\n",
    "![](https://1.bp.blogspot.com/-CThvwj-LRq4/WuucqLXkYII/AAAAAAAAAlw/LYRt4pkuu4wnyw6BGV9H0bSIZ4HRmdJ2gCEwYBhgL/s1600/Screen%2BShot%2B2018-05-04%2Bat%2B8.30.40%2BAM.png)\n",
    "(출처: https://developers-kr.googleblog.com/2018/05/eager-execution.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Tensorflow & Check the Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello World example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'hello world', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# Create a constant Tensor\n",
    "hello = tf.constant(\"hello world\")\n",
    "print(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hello world'\n"
     ]
    }
   ],
   "source": [
    "# To access the Tensor value, call numpy().\n",
    "print(hello.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Tensor Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tensor constants.\n",
    "a = tf.constant(2)\n",
    "b = tf.constant(3)\n",
    "c = tf.constant(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add = 5\n",
      "sub = -1\n",
      "mul = 6\n",
      "div = 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Various tensor operations.\n",
    "# Note: Tensors also support python operators (+, *, ...)\n",
    "add = tf.add(a, b)\n",
    "sub = tf.subtract(a, b)\n",
    "mul = tf.multiply(a, b)\n",
    "div = tf.divide(a, b)\n",
    "\n",
    "# Access tensors value.\n",
    "print(\"add =\", add.numpy())\n",
    "print(\"sub =\", sub.numpy())\n",
    "print(\"mul =\", mul.numpy())\n",
    "print(\"div =\", div.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 3\n",
      "sum = 10\n"
     ]
    }
   ],
   "source": [
    "# Some more operations.\n",
    "mean = tf.reduce_mean([a, b, c])\n",
    "sum_ = tf.reduce_sum([a, b, c])\n",
    "\n",
    "# Access tensors value.\n",
    "print(\"mean =\", mean.numpy())\n",
    "print(\"sum =\", sum_.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplications.\n",
    "matrix1 = tf.constant([[1., 2.], [3., 4.]])\n",
    "matrix2 = tf.constant([[5., 6.], [7., 8.]])\n",
    "\n",
    "product = tf.matmul(matrix1, matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=26, shape=(2, 2), dtype=float32, numpy=\n",
       "array([[19., 22.],\n",
       "       [43., 50.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display Tensor.\n",
    "product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19., 22.],\n",
       "       [43., 50.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Tensor to Numpy.\n",
    "product.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy와 Tensorflow의 데이터 배열\n",
    "- `tf.Tensor` vs. `np.ndarray`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.Tensor`는 numpy array와 달리 GPU (혹은 TPU)에서 사용할 수 있다.\n",
    "- 각각의 `tf.Tensor`는 크기와 데이터 타입을 가지고 있다.\n",
    "- `tf.Tensor`는 `.numpy()` 메서드를 통해 numpy array로 변환할 수 있다.\n",
    "  - 즉시 실행 (eager execution) 개념의 도입으로 두 데이터 타입 간 호환성이 높아짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서플로 연산은 자동적으로 넘파이 배열을 텐서로 변환합니다.\n",
      "tf.Tensor(\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
      "\n",
      "각각의 텐서는 크기와 데이터 타입을 가지고 있습니다.\n",
      "(3, 3)\n",
      "<dtype: 'float64'>\n",
      "\n",
      "그리고 넘파이 연산은 자동적으로 텐서를 넘파이 배열로 변환합니다.\n",
      "[[43. 43. 43.]\n",
      " [43. 43. 43.]\n",
      " [43. 43. 43.]]\n",
      "\n",
      ".numpy() 메서드는 텐서를 넘파이 배열로 변환합니다.\n",
      "[[42. 42. 42.]\n",
      " [42. 42. 42.]\n",
      " [42. 42. 42.]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "ndarray = np.ones([3, 3])\n",
    "\n",
    "print(\"텐서플로 연산은 자동적으로 넘파이 배열을 텐서로 변환합니다.\")\n",
    "tensor = tf.multiply(ndarray, 42)\n",
    "print(tensor)\n",
    "print()\n",
    "\n",
    "print('각각의 텐서는 크기와 데이터 타입을 가지고 있습니다.')\n",
    "print(tensor.shape)\n",
    "print(tensor.dtype)\n",
    "print()\n",
    "\n",
    "print(\"그리고 넘파이 연산은 자동적으로 텐서를 넘파이 배열로 변환합니다.\")\n",
    "print(np.add(tensor, 1))\n",
    "print()\n",
    "\n",
    "print(\".numpy() 메서드는 텐서를 넘파이 배열로 변환합니다.\")\n",
    "print(tensor.numpy())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU를 사용한 연산 가속화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서플로는 연산을 위해 자동적으로 CPU 또는 GPU를 사용할 것인지를 정합니다.\n",
    "- 그리고 필요시 텐서를 CPU 와 GPU에 복사합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 사용이 가능한가 : \n",
      "True\n",
      "텐서가 GPU #0에 있는가 :  \n",
      "True\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform([3, 3])\n",
    "\n",
    "print(\"GPU 사용이 가능한가 : \"),\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "print(\"텐서가 GPU #0에 있는가 :  \"),\n",
    "print(x.device.endswith('GPU:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주어진 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our data\n",
    "train_x = [1,2,3,4]\n",
    "train_y = [0,-1,-2,-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델 및 손실함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight and Bias: initialized with fixed values.\n",
    "W = tf.Variable([.3], dtype=tf.float32, name=\"weight\")\n",
    "b = tf.Variable([-.3], dtype=tf.float32, name=\"bias\")\n",
    "\n",
    "# Weight and Bias: initialized randomly.\n",
    "# W = tf.Variable(rng.randn(), name=\"weight\")\n",
    "# b = tf.Variable(rng.randn(), name=\"bias\")\n",
    "\n",
    "# a simple linear model\n",
    "def linear_model(x):\n",
    "    return x * W + b\n",
    "\n",
    "# Mean square error.\n",
    "def mean_square_loss(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.pow(y_pred-y_true, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 현재 모델의 예측값 및 손실함수값 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   [1, 2, 3, 4]\n",
      "y_true:  [0, -1, -2, -3]\n",
      "y_pred:  [0.         0.3        0.6        0.90000004]\n",
      "loss:    5.9150004\n"
     ]
    }
   ],
   "source": [
    "# compute all at once.\n",
    "yhat = linear_model(train_x)\n",
    "loss = mean_square_loss(yhat, train_y)\n",
    "print('input:  ', train_x)\n",
    "print('y_true: ', train_y)\n",
    "print('y_pred: ', yhat.numpy())\n",
    "print('loss:   ', loss.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   1\n",
      "y_true:  0\n",
      "y_pred:  [0.]\n",
      "loss:    0.0\n",
      "\n",
      "input:   2\n",
      "y_true:  -1\n",
      "y_pred:  [0.3]\n",
      "loss:    1.6899998\n",
      "\n",
      "input:   3\n",
      "y_true:  -2\n",
      "y_pred:  [0.6]\n",
      "loss:    6.7599993\n",
      "\n",
      "input:   4\n",
      "y_true:  -3\n",
      "y_pred:  [0.90000004]\n",
      "loss:    15.210001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# compute separately.\n",
    "for x, y in zip(train_x, train_y):\n",
    "    yhat = linear_model(x)\n",
    "    loss = mean_square_loss(yhat, y)\n",
    "    print('input:  ', x)\n",
    "    print('y_true: ', y)\n",
    "    print('y_pred: ', yhat.numpy())\n",
    "    print('loss:   ', loss.numpy())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 손으로 최적해 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x195cfacb320>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# data visualization\n",
    "plt.scatter(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   [1, 2, 3, 4]\n",
      "y_true:  [0, -1, -2, -3]\n",
      "y_pred:  [ 0. -1. -2. -3.]\n",
      "loss:    0.0\n"
     ]
    }
   ],
   "source": [
    "fixW = W.assign([-1.])\n",
    "fixb = b.assign([1.])\n",
    "\n",
    "def solution_model(x):\n",
    "    return x * fixW + fixb\n",
    "\n",
    "yhat = solution_model(train_x)\n",
    "loss = mean_square_loss(yhat, train_y)\n",
    "\n",
    "print('input:  ', train_x)\n",
    "print('y_true: ', train_y)\n",
    "print('y_pred: ', yhat.numpy())\n",
    "print('loss:   ', loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그렇지만, 차원이 크고 관계가 복잡하다면...?\n",
    "\n",
    "#### 데이터를 잘 설명하는 최적의 w, b를 찾기 위한 학습 과정이 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stochastic gradient descent optimizer.\n",
    "learning_rate = 0.1\n",
    "optimizer = tf.optimizers.SGD(learning_rate)\n",
    "\n",
    "# Optimization process. \n",
    "def run_optimization(x, y):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = linear_model(x)\n",
    "        loss = mean_square_loss(pred, y)\n",
    "\n",
    "    # Compute gradients.\n",
    "    trainable_variables = [W, b]\n",
    "    gradients = g.gradient(loss, trainable_variables)\n",
    "    \n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.000000\n",
      "step: 20, loss: 0.000000\n",
      "step: 40, loss: 0.000000\n",
      "step: 60, loss: 0.000000\n",
      "step: 80, loss: 0.000000\n"
     ]
    }
   ],
   "source": [
    "for step in range(100):\n",
    "    for x, y in zip(train_x, train_y):\n",
    "        # Run the optimization to update W and b values.\n",
    "        run_optimization(x, y)\n",
    "\n",
    "    yhat = linear_model(train_x)\n",
    "    loss = mean_square_loss(yhat, train_y)\n",
    "    if step % 20==0:\n",
    "        print(\"step: %i, loss: %f\" % (step, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:   [1, 2, 3, 4]\n",
      "y_true:  [0, -1, -2, -3]\n",
      "y_pred:  [ 0. -1. -2. -3.]\n",
      "loss:    0.0\n"
     ]
    }
   ],
   "source": [
    "yhat = linear_model(train_x)\n",
    "loss = mean_square_loss(yhat, train_y)\n",
    "print('input:  ', train_x)\n",
    "print('y_true: ', train_y)\n",
    "print('y_pred: ', yhat.numpy())\n",
    "print('loss:   ', loss.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
